<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>He Xingwei's Homepage</title>
  <link href="css/bootstrap.css" rel='stylesheet' type='text/css' />
  <!--<link rel="shortcut icon" href="../images/fav_icon.png" type="image/x-icon">-->
  <link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">
  <!-- Bulma Version 0.7.5-->
  <link rel="stylesheet" href="https://unpkg.com/bulma@0.7.5/css/bulma.min.css" />
  <link href='css/style.css?_t=20200916' rel='stylesheet' type='text/css'>
  <script defer src="font-awesome-5.9.0/js/brands.min.js"></script>
  <script defer src="font-awesome-5.9.0/js/fontawesome.min.js"></script>
    <style>
      .red {
        color: #ff0000;
        font-style: normal;
      }
       
      #intro {
       margin-top: 0.2em !important;
      }
      
      .content h3 {
       margin-bottom: 1em!important;
       margin-top: 2.5em!important;
      }

      .content figure {
       width: 90%;
       display: flex;
       align-items: center;
       overflow: hidden;
       margin-left: auto!important;
       margin-right: auto!important;
      }
      
      .columns:not(:last-child) {
       margin-bottom: 1.75rem!important;
      }

      #sidebar {
        width: 80%;
      }

      <!--#sidebar .menu-list a.is-active {-->
      <!--  background-color: #9dd5d8;-->
      <!--}-->

      @media screen and (min-width: 769px), print {
        .column.is-2_5, .column.is-2-tablet {
          flex: none;
          width: 20%;
        }
      }
</style>
    <script src="https://code.jquery.com/jquery-3.1.1.min.js" crossorigin="anonymous"></script>
</head>


<body>
  <section class="section">
    <div class="container">
      <div class="columns">
        <div class="column is-2_5">
          <div class="sticky">
            <figure class="image" style="width: 10rem;">
              <img class="is-rounded" src="images/hxw.jpg">
            </figure>
            <div class="content">
              <h3 style="margin-top: 1em">He Xingwei (贺星伟)</h3>
	      <h8>Chow Yei Ching Building,</h8>
              <h8>The University of Hong Kong,</h8>
              <h8>Pokfulam Road, Hong Kong</h8>

            </div>
            <!-- details -->
            <div class="details">
              <h3>Email:</h3>
              <p><a href="mailto:hexingwei15@gmail.com">hexingwei15[at]gmail[dot]com</a></p>
            </div>
            <!-- social network icons -->
            <div class="social">
              <a href="https://github.com/NLPCode" target="_blank">
                <span class="fab fa-github fa-2x" style="display:inline; text-decoration: none"></span>
              </a>
              <a href="https://scholar.google.com/citations?user=p1a5WXIAAAAJ&hl=zh-TW" target="_blank">
                <span class="fab fa-google fa-2x" style="display:inline; text-decoration: none"></span>
              </a>
<!--               <a href="https://www.linkedin.com/in/yuan-yuan-96451747/" target="_blank">
                <span class="fab fa-linkedin fa-2x" style="display:inline; text-decoration: none"></span>
              </a>
              <a href="https://twitter.com/miayuany" target="_blank">
                <span class="fab fa-twitter fa-2x" style="display:inline; text-decoration: none"></span>
              </a> -->
            </div>


            <div id="sidebar" class="menu sticky is-hidden-mobile">
              <p class="menu-label"><b>Quick Links</b></p>
              <ul class="menu-list">
                <li><a href="#intro">About Me</a></li>
                <li><a href="#news">News</a></li>
                <li><a href="#publications">Publications</a></li>
                <li><a href="#miscellaneous">Miscellaneous</a></li>
              </ul>
              <div class="column" style="width: 40%">
<!-- 		<script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=6v6vvEAKRqz8Jrlvk90FIvLa7XS1oXlcqWmZP2aKx9Y&cl=ffffff&w=a"></script> -->
		<script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=6v6vvEAKRqz8Jrlvk90FIvLa7XS1oXlcqWmZP2aKx9Y"></script>
              </div>
            </div>
          </div>



        </div>
        <div class="column right-panel">
          <div class="content">


            <!--About Me-->
            <h3 id="intro">About Me</h3>
            <p>I am a Ph.D. student at <a href="https://www.cs.hku.hk/" target="_blank">Computer Science</a>
              of <a href="https://www.hku.hk//" target="_blank">the University of Hong Kong (HKU)</a>, working with <a href="https://www.cs.hku.hk/people/academic-staff/smyiu" target="_blank">Prof. Yiu, Siu Ming</a>.
<!--               Before HKU, I obtained my Ph.D. degree in <a href="https://ece.hkust.edu.hk/" target="_blank">ECE department</a> from <a href="http://www.ust.hk/" target="_blank">Hong Kong University of Science and Technology</a>, advised by Prof. <a href="https://sites.google.com/view/dyyeung" target="_blank">Dit-Yan Yeung</a>.
              I was a visiting research scholar in <a href="https://www.ri.cmu.edu/" target="_blank">The Robotics Institute</a> of <a href="http://www.cmu.edu/" target="_blank">Carnegie Mellon University</a>, working with Prof. <a href="http://www.cs.cmu.edu/~abhinavg/" target="_blank">Abhinav Gupta</a>.
 -->
            </p>

            <p>
              My research interests mainly focus on topic modeling, lexically constrained text generation and information retrieval. In short, topic modeling is meant to infer the latent topics from the given documents; lexically constrained text generation aims to generate plausible and grammatical sentences under the given keywords; and information retrieval is to fetch top relevant documents from a huge collection for the input query.
            </p>
            

            <!--News-->
            <h3 id="news">
              News
            </h3>
            <ul>
		    
	     <li><span>[03/2024] Our paper <a href="https://arxiv.org/abs/2303.16854" target="_blank">"AnnoLLM: Making Large Language Models to Be Better Crowdsourced Annotators"</a> has been accepted to NAACL 2024.</span></li>
	     <li><span>[02/2024] Our paper <a href="https://ojs.aaai.org/index.php/AAAI/article/view/29778/" target="_blank">"Knowledge Enhanced Pre-training for Cross-lingual Dense Retrieval"</a> has been accepted to COLING 2024.</span></li>
	     <li><span>[12/2023] Our paper <a href="https://ojs.aaai.org/index.php/AAAI/article/view/29778/" target="_blank">"Improving Factual Error Correction by Learning to Inject Factual Errors"</a> has been accepted to AAAI 2024.</span></li>
	     <li><span>[10/2023] Our paper <a href="https://aclanthology.org/2023.emnlp-main.651/" target="_blank">"CAPSTONE: Curriculum Sampling for Dense Retrieval with Document Expansion"</a> has been accepted to EMNLP 2023 (<b>Long Paper</b>).</span></li>
	     <li><span>[10/2023] Our paper <a href="https://aclanthology.org/2023.findings-emnlp.667/" target="_blank">"PivotFEC: Enhancing Few-shot Factual Error Correction with a Pivot Task Approach using Large Language Models"</a> has been accepted to the Findings of EMNLP 2023 (<b>Long Paper</b>).</span></li>
	     <li><span>[10/2023] Our paper <a href="https://aclanthology.org/2023.findings-emnlp.765/" target="_blank">"Noisy Pair Corrector for Dense Retrieval"</a> has been accepted to the Findings of EMNLP 2023 (<b>Long Paper</b>).</span></li>
	     
	     <li><span>[10/2022] Our paper <a href="https://arxiv.org/abs/2210.11708" target="_blank">"Metric-guided Distillation: Distilling Knowledge from the Metric to Ranker and Retriever for Generative Commonsense Reasoning"</a> has been accepted to EMNLP 2022 (<b>Long Paper</b>).</span></li>
	     <em class="red"><b>Oral Presentation </b></em><br>
	     <li><span>[06/2022] Our model <a href="https://arxiv.org/abs/2210.11708" target="_blank"> DKMR^2</a> achieves the SOTA on the <a href="https://inklab.usc.edu/CommonGen/leaderboard.html" target="_blank"> CommonGen leaderboard</a>. </span></li>
		    
              <li><span>[02/2022] Our paper <a href="https://aclanthology.org/2022.acl-long.46/" target="_blank">"Controllable Dictionary Example Generation: Generating Example Sentences for Specific Targeted Audiences"</a> has been accepted to ACL 2022 (<b>Long Paper</b>).</span></li>
	     <li><span>[08/2021] Our paper <a href="https://aclanthology.org/2021.emnlp-main.681/" target="_blank">"Parallel Refinements for Lexically Constrained Text Generation with BART"</a> has been accepted to EMNLP 2021 (<b>Long Paper</b>).</span></li>
	     <li><span>[12/2020] Our paper <a href="https://ojs.aaai.org/index.php/AAAI/article/view/17536" target="_blank">"Show Me How To Revise: Improving Lexically Constrained Sentence Generation with XLNet"</a> has been accepted to AAAI 2021.</span></li>

            </ul>


            <!--Selected Publications-->
<!--             <h3 id="publications">Selected Publications <span style="font-size: 1rem;margin-left: 1rem;position: relative;bottom: .1rem;"><a href="https://scholar.google.com/citations?user=9tI89HMAAAAJ" target="_blank">[Full List]</a></span></h3>
            
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/2022_tokencut.gif">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>Self-Supervised Transformers for Unsupervised Object Discovery using Normalized Cut </b><br>
                    <a href="https://yangtaowang95.github.io/" target="_blank" class="dark">Yangtao Wang</a>, <a href="https://xishen0220.github.io/" target="_blank" class="dark">Xi Shen</a>, <a href="http://hushell.github.io/" target="_blank" class="dark">Xu Hu</a>, <b>Yuan Yuan</b>, <a href="http://crowley-coutaz.fr/jlc/jlc.html" target="_blank" class="dark">James Crowley</a>, <a href="https://research.vaufreydaz.org/" target="_blank" class="dark">Dominique Vaufreydaz</a><br>
                    <i>Computer Vision and Pattern Recognition (<b>CVPR</b>), 2022</i><br>
                    <i>Workshop on Learning with Limited Labelled Data for Image and Video Understanding (<b>CVPR</b>), 2022</i><bi>
                    <a href="https://www.m-psi.fr/Papers/TokenCut2022/" target="_blank">[Project Page]</a>
                    <a href="https://arxiv.org/pdf/2202.11539.pdf" target="_blank">[arXiv]</a>
                    <a href="https://github.com/YangtaoWANG95/TokenCut" target="_blank">[Code (GitHub)]</a>
                    <a href="https://gricad-gitlab.univ-grenoble-alpes.fr/wangyan/tokencut" target="_blank">[Code (GitLab)]</a>
                    <a href='https://colab.research.google.com/github/YangtaoWANG95/TokenCut/blob/master/inference_demo.ipynb'><img alt="Queries" src="https://colab.research.google.com/assets/colab-badge.svg"></a>
		    <a href='https://huggingface.co/spaces/akhaliq/TokenCut'><img alt="Queries" src="https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue"></a>    
                  </p>
                </div>
              </div>
            </article>
		  
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/2022_Target_SupCon.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>Targeted Supervised Contrastive Learning for Long-Tailed Recognition</b><br>
                    <a href="http://www.tianhongli.me/" target="_blank" class="dark">Tianhong Li*</a>, <a href="https://scholar.google.com/citations?user=UlaXT00AAAAJ&hl=en" target="_blank" class="dark">Peng Cao*</a>, <b>Yuan Yuan</b>, <a href="http://lijiefan.me/" target="_blank" class="dark">Lijie Fan</a>, <a href="https://www.mit.edu/~yuzhe/" target="_blank" class="dark">Yuzhe Yang</a>, <a href="https://www.rogerioferis.org/" target="_blank" class="dark">Rogerio Feris</a>, Piotr Indyk and Dina Katabi<br>
                    <i>Computer Vision and Pattern Recognition (<b>CVPR</b>), 2022</i><br>
                    <a href="https://arxiv.org/abs/2111.13998.pdf" target="_blank">[arXiv]</a>
                  </p>
                </div>
              </div>
            </article>
            
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/2022_rcl.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>Addressing Feature Suppression in Unsupervised Visual Representations</b><br>
                    <a href="http://www.tianhongli.me/" target="_blank" class="dark">Tianhong Li*</a>, <a href="http://lijiefan.me/" target="_blank" class="dark">Lijie Fan*</a>, <b>Yuan Yuan</b>, <a href="http://people.csail.mit.edu/hehaodele/" target="_blank" class="dark">Hao He</a>, <a href="https://people.csail.mit.edu/yonglong/" target="_blank" class="dark">Yonglong Tian</a>, <a href="https://www.rogerioferis.org/" target="_blank" class="dark">Rogerio Feris</a>, Piotr Indyk and Dina Katabi<br>
                    <i>arXiv:2012.09962, 2021</i><br>
                    <a href="https://arxiv.org/pdf/2012.09962.pdf" target="_blank">[arXiv]</a>
                    <a href="https://www.youtube.com/watch?v=wbtAOIS16LY" target="_blank">[Talk]</a>
                  </p>
                </div>
              </div>
            </article>
            
            
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/2022_wacv_rfrcl.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>Unsupervised Learning for Human Sensing Using Radio Signals</b><br>
                    <a href="http://www.tianhongli.me/" target="_blank" class="dark">Tianhong Li*</a>, <a href="http://lijiefan.me/" target="_blank" class="dark">Lijie Fan*</a>, <b>Yuan Yuan*</b> and Dina Katabi<br>
                    <i>Winter Conference on Applications of Computer Vision (<b>WACV</b>), 2022</i><br>
                    <a href="https://openaccess.thecvf.com/content/WACV2022/papers/Li_Unsupervised_Learning_for_Human_Sensing_Using_Radio_Signals_WACV_2022_paper.pdf" target="_blank">[PDF]</a>
                    <a href="papers/poster_2022_wacv_RF_Unsup.pdf" target="_blank">[Poster]</a>
                    <a href="bib/2022_wacv_RF_Unsup.txt" target="_blank">[BibTeX]</a>
                  </p>
                </div>
              </div>
            </article>
            
            
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/2020_neurips_rank_1_lattice.png">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>Subgroup-based Rank-1 Lattice Quasi-Monte Carlo</b><br>
                    <a href="https://yueminglyu.github.io/" target="_blank" class="dark">Yueming Lyu</a>, <b>Yuan Yuan</b> and Ivor W. Tsang<br>
                    <i>Thirty-fourth Conference on Neural Information Processing Systems (<b>NeurIPS</b>), 2020</i><br>
                    <a href="https://proceedings.neurips.cc/paper/2020/file/456048afb7253926e1fbb7486e699180-Paper.pdf" target="_blank">[Paper]</a>
                    <a href="https://proceedings.neurips.cc/paper/2020/file/456048afb7253926e1fbb7486e699180-Supplemental.zip" target="_blank">[Supplemental]</a>
                    <a href="https://arxiv.org/pdf/2011.06446.pdf" target="_blank">[arXiv]</a>
                    <a href="papers/poster_2020_neurips_Lattice.pdf" target="_blank">[Poster]</a>
                  </p>
                </div>
              </div>
            </article>


            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/2020_eccv_rf_diary.png">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>In-home Daily-Life Captioning Using Radio Signals</b><br>
                    <a href="http://lijiefan.me/" target="_blank" class="dark">Lijie Fan*</a>, <a href="http://www.tianhongli.me/" target="_blank" class="dark">Tianhong Li*</a>, <b>Yuan Yuan</b> and Dina Katabi<br>
                    <i>European Conference on Computer Vision (<b>ECCV</b>), 2020</i><br>
                    <a href="http://rf-diary.csail.mit.edu/" target="_blank">[Project Page]</a>
                    <a href="http://rf-diary.csail.mit.edu/papers/rfdiary_eccv.pdf" target="_blank">[PDF]</a>
                    <a href="https://arxiv.org/abs/2008.10966" target="_blank">[arXiv]</a>
                    <a href="http://rf-diary.csail.mit.edu/slides/longtalk.pdf" target="_blank">[Slides]</a>
                    <a href="https://www.youtube.com/watch?v=j528nQs4_a8&feature=youtu.be" target="_blank">[Demo]</a>
                    <a href="https://www.youtube.com/watch?v=LA-JW4_ovAQ&feature=youtu.be" target="_blank">[Video]</a>
                    <a href="https://www.youtube.com/watch?v=S2Y-zPJnl9U&feature=youtu.be" target="_blank">[Talk]</a>
                    <a href="https://www.csail.mit.edu/news/device-nursing-homes-can-monitor-residents-activities-permission-and-without-video" target="_blank">[MIT CSAIL News]</a>
                    <a href="http://mms.tveyes.com/MediaCenterPlayer.aspx?u=aHR0cDovL21lZGlhY2VudGVyLnR2ZXllcy5jb20vZG93bmxvYWRnYXRld2F5LmFzcHg/VXNlcklEPTMwMzQ3OCZNRElEPTEzNzExMTM5Jk1EU2VlZD0yNTU0JlR5cGU9TWVkaWE%3D" target="blank">[BBC]</a>
                    <a href="https://techcrunch.com/2020/08/24/mit-wireless-system-can-monitor-what-care-facility-residents-are-doing-while-preserving-privacy/" target="_blank">[TechCrunch]</a>
                    <a href="https://www.engadget.com/mit-wireless-signals-monitoring-machine-learning-rf-diary-040049578.html" target="_blank">[Engadget]</a>
                    <a href="https://venturebeat.com/2020/08/24/mit-csails-rf-diary-monitors-people-through-walls-and-in-total-darkness/" target="_blank">[VentureBeat]</a><br>
                    <em class="red"><b>Oral Presentation (2%)</b></em><br>
                  </p>
                </div>
              </div>
            </article>


            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/2020_cvpr_rf_reid.png">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>Learning Longterm Representations for Person Re-Identification Using Radio Signals</b><br>
                    <a href="http://lijiefan.me/" target="_blank" class="dark">Lijie Fan*</a>, <a href="http://www.tianhongli.me/" target="_blank" class="dark">Tianhong Li*</a>, <a href="https://rongyaofang.github.io/" target="_blank" class="dark">Rongyao Fang*</a>, Rumen Hristov, <b>Yuan Yuan</b> and Dina Katabi<br>
                    <i>Computer Vision and Pattern Recognition (<b>CVPR</b>), 2020</i><br>
                    <a href="http://rf-reid.csail.mit.edu/" target="_blank">[Project Page]</a>
                    <a href="http://rf-reid.csail.mit.edu/papers/rfreid_cvpr.pdf" target="_blank">[PDF]</a>
                    <a href="https://arxiv.org/abs/2004.01091" target="_blank">[arXiv]</a>
                    <a href="https://www.youtube.com/watch?v=oYv30obQ8P4&feature=youtu.be" target="_blank">[Video]</a>
                    <a href="https://www.csail.mit.edu/news/home-health-device-uses-wireless-signals-identify-person-its-seen" target="_blank">[MIT CSAIL News]</a>
                    <a href="https://techcrunch.com/2020/06/16/mits-new-way-to-remotely-monitor-vital-signs-over-time-could-help-with-early-covid-19-detection-in-care-homes/" target="_blank">[TechCrunch]</a>
                    <a href="https://www.yahoo.com/lifestyle/mits-way-remotely-monitor-vital-132517815.html" target="_blank">[Yahoo News]</a>
		    <a href="https://www.healthcareitnews.com/news/mit-csail-machine-learning-tool-could-help-nursing-homes-predict-covid-19" target="_blank">[Healthcare IT News]</a>
                  </p>
                </div>
              </div>
            </article>

            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/2019_iclr_maan.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>Marginalized Average Attentional Network For Weakly-Supervised Learning</b><br>
                    <b>Yuan Yuan</b>, <a href="https://yueminglyu.github.io/" target="_blank" class="dark">Yueming Lyu</a>, <a href="https://xishen0220.github.io/" target="_blank" class="dark">Xi Shen</a>, Ivor W. Tsang and Dit-Yan Yeung<br>
                    <i>International Conference on Learning Representations (<b>ICLR</b>), 2019</i><br>
                    <a href="https://arxiv.org/pdf/1905.08586.pdf" target="_blank">[PDF]</a>
                    <a href="https://github.com/yyuanad/MAAN" target="_blank">[Code]</a>
		    <a href="bib/2019_iclr_maan.txt" target="_blank">[BibTeX]</a> 
                  </p>
                </div>
              </div>
            </article>

            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/2019_jmlr_yueming.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>Efficient Batch Black-box Optimization with Deterministic Regret Bounds</b><br>
                    <a href="https://yueminglyu.github.io/" target="_blank" class="dark">Yueming Lyu</a>, <b>Yuan Yuan</b> and Ivor W. Tsang<br>
                    <i> Under Review (<b>JMLR</b>), 2019</i><br>
                    <a href="https://arxiv.org/pdf/1905.10041.pdf" target="_blank">[arXiv]</a>
                  </p>
                </div>
              </div>
            </article>

            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/2017_iccv_TD_GraphLSTM.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>Temporal Dynamic Graph LSTM for Action-driven Video Object Detection</b><br>
                    <b>Yuan Yuan</b>, Xiaodan Liang, Xiaolong Wang, Dit-Yan Yeung and Abhinav Gupta<br>
                    <i>International Conference on Computer Vision (<b>ICCV</b>), 2017</i><br>
                    <a href="https://openaccess.thecvf.com/content_ICCV_2017/papers/Yuan_Temporal_Dynamic_Graph_ICCV_2017_paper.pdf" target="_blank">[PDF]</a>
                    <a href="https://github.com/xiaolonw/CharadesDet" target="_blank">[Dataset]</a>
                    <a href="bib/2017_iccv_TD_GraphLSTM.txt" target="_blank">[BibTeX]</a>
                  </p>
                </div>
              </div>
            </article>

            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/2016_tcsvt_amin.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>Adaptive Block Coding Order for Intra Prediction in HEVC</b><br>
                    Amin Zheng, <b>Yuan Yuan</b>, Jiantao Zhou, Yuanfang Guo, Haitao Yang and Oscar C. Au<br>
                    <i>IEEE Transaction on Circuits and Systems for Video Technology, vol.26, no.11, pp.2152-2158, Nov. (<b>TCSVT</b>), 2016</i><br>
                    <a href="papers/paper_2016_TCSVT_amin.pdf" target="_blank">[PDF]</a><br>
                  </p>
                </div>
              </div>
	</article>
 -->



<!--             <h3 >
              Patents and Patent Applications
            </h3>
            <ul>
              <li><b>Voice interaction system, related method, device and equipment</b> <a href="https://patents.google.com/patent/CN113160854A/en?oq=CN113160854" target="_blank">[Google Patent Page]</a></li>
              <a href="https://patentimages.storage.googleapis.com/a4/5a/80/eedd7ce7d28416/CN113160854A.pdf" target="_blank">CN113160854</a>, Jan. 2020.
              
              <li><b>Voice processing method, model training method, interface display method and equipment</b> <a href="https://patents.google.com/patent/CN112825248A/en?oq=CN112825248" target="_blank">[Google Patent Page]</a></li>
              <a href="https://patentimages.storage.googleapis.com/a5/6f/ac/6cf253d225b6c8/CN112825248A.pdf" target="_blank">CN112825248</a>, Nov. 2019.

              <li><b>Method and device for processing action behaviors in video</b> <a href="https://patents.google.com/patent/CN110096938A/en?oq=CN110096938" target="_blank">[Google Patent Page]</a></li>
              <a href="https://patentimages.storage.googleapis.com/03/82/3a/874a0e4d7dd60d/CN110096938A.pdf" target="_blank">CN110096938</a>, Jan. 2018.
              
              <li><b>Encoding and decoding methods and apparatuses</b> <a href="https://patents.google.com/patent/US20160373767A1/en" target="_blank">[Google Patent Page]</a></li>
              <a href="https://patentimages.storage.googleapis.com/0f/12/3d/4bade0b838d237/KR101960825B1.pdf" target="_blank">KR101960825</a>, granted Mar. 2019;
              <a href="https://patentimages.storage.googleapis.com/48/b8/db/9c9af2352843be/CN104853196B.pdf" target="_blank">CN104853196</a>, granted Oct. 2018; 
              <a href="https://patentimages.storage.googleapis.com/62/a3/61/0d95dc00cc3003/JP6389264B2.pdf" target="_blank">JP6389264</a>, granted Sep. 2018; 
              <a href="https://patentimages.storage.googleapis.com/7b/d4/47/7c2901d8f38217/US20160373767A1.pdf" target="_blank">US20160373767</a>, Dec. 2016;
              <a href="https://patentimages.storage.googleapis.com/f3/54/63/bbc84aebe4e87b/EP3094091A1.pdf" target="_blank">EP3094091A1</a>, Nov. 2016; 
              <a href="https://patentimages.storage.googleapis.com/21/16/95/6271e1f6b8a679/WO2015124058A1.pdf" target="_blank">WO2015124058</a>, Aug. 2015.  
            </ul> -->
            
            <h3 id="miscellaneous">
              Selected Honors and Awards
            </h3>
            <ul>
              <li>Postgraduate Scholarship at the University of Hong Kong, 2018, 2019, 2021, 2022.</li>
              <li>First Prize of ACM/ICPC Program Contest at Xidian University, 2014.</li>
              <li>First Prize of Higher Mathematics Competition in Shanxi Province, 2012.</li>
              <li>National Scholarship, Ministry of Education of P.R. China, 2011, 2012, 2013.</li>
              <li>Excellent Student at Xidian University, 2011, 2012, 2013.</li>
            </ul>


            <h3 >
              Academic Services
            </h3>
            <ul>

              <li><b>Conference Reviewer:</b></li>

              AAAI Conference on Artificial Intelligence (AAAI), 2021. <br>
	      North American Chapter of the Association for Computational Linguistics (NAACL), 2022. <br>
	      Empirical Methods in Natural Language Processing  (EMNLP), 2022. <br>
		    


              <li><b>Journal Reviewer</b></li>
              IEEE Transactions on Emerging Topics in Computational Intelligence, 2022. <br>
              Applied Intelligence, 2021. <br>

            </ul>


            <h3 >
              Teaching
            </h3>
<!--             Duties at various times have included: weekly tutorial classes, weekly computer lab exercises, office hours, mark homework and exam papers. -->
            <ul>
              <li>Teaching Assistant (Tutor and Grader) at the University of Hong Kong -- Electronic Commerce Technology (COMP3320), <i>Spring 2022</i>. </li>
              <li>Teaching Assistant (Tutor) at the University of Hong Kong -- Computer Programming I (ENGG1330), <i>Spring 2021</i>. </li>
	      <li>Teaching Assistant (Tutor) at the University of Hong Kong -- Computer Programming I (ENGG1330), <i>Spring 2020</i>. </li>
	      <li>Teaching Assistant (Demonstrator) at the University of Hong Kong -- MIC Training, <i>Summer 2019</i>. </li>
		    
            </ul>

            
          </div>
        </div>
      </div>
    </div>

    <!-- Footer -->
    <footer class="container">
      <br><hr>
      <div class="row" style="text-align: center">
        ©2022 He Xingwei. Last updated: Oct 26, 2022.
      </div>
    </footer>
  </section>


  <script>

    var $hashList = $('.menu-list a'), offsetList, maxScrollHeight;

    $('#sidebar').on('click', 'a', function(){
      activate($(this))
    });
    
    $(window).on('resize', debounce(calculateBoundary, 300));

    $(document).on('scroll', debounce(judgeScroll, 300));

    calculateBoundary();
    judgeScroll();
    
    function  calculateBoundary() {
      offsetList = $hashList.map(function(idx, ele){
        return $(ele.hash).offset().top
      });
      maxScrollHeight = $(document).height() - $(window).height()
    }
    
    function judgeScroll() {
      var tps = $("html").scrollTop()
              ? $("html").scrollTop()
              : $("body").scrollTop(),
              len = offsetList.length;
      if(tps >= maxScrollHeight-10){
        activate($hashList.eq(len-1));
        return
      }
      for(var i=0; i<len; i++){
       if(tps+50<offsetList[i]){
          activate($hashList.eq(Math.max(0,i-1)));
          return
        }
      }
    }

    function activate(ele){
      $hashList.removeClass('is-active');
      ele.addClass('is-active');
    }

    function debounce(fn, delay) {
      var timeout = null;
      return function () {
        var args = arguments;
        var context = this;
        if (!timeout) {
          timeout = setTimeout(function () {
            timeout = 0;
            return fn.apply(context, args);
          }, delay);
        }
      };
    }



  </script>


</body>

</html>
